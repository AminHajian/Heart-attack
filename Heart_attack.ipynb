{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I will use :\n",
    "- KNN \n",
    "- Decision Trees\n",
    "- Logistic Regression\n",
    "- SVM :\n",
    "    - poly\n",
    "    - linear\n",
    "    - sigmoid\n",
    "    - rbf\n",
    "\n",
    "#### add primary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0     63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1     37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2     41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3     56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4     57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n",
       "298   57    0   0     140   241    0        1       123     1      0.2    1   \n",
       "299   45    1   3     110   264    0        1       132     0      1.2    1   \n",
       "300   68    1   0     144   193    1        1       141     0      3.4    1   \n",
       "301   57    1   0     130   131    0        1       115     1      1.2    1   \n",
       "302   57    0   1     130   236    0        0       174     0      0.0    1   \n",
       "\n",
       "     caa  thall  output  \n",
       "0      0      1       1  \n",
       "1      0      2       1  \n",
       "2      0      2       1  \n",
       "3      0      2       1  \n",
       "4      0      2       1  \n",
       "..   ...    ...     ...  \n",
       "298    0      3       0  \n",
       "299    0      3       0  \n",
       "300    2      3       0  \n",
       "301    1      3       0  \n",
       "302    1      2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex           int64\n",
       "cp            int64\n",
       "trtbps        int64\n",
       "chol          int64\n",
       "fbs           int64\n",
       "restecg       int64\n",
       "thalachh      int64\n",
       "exng          int64\n",
       "oldpeak     float64\n",
       "slp           int64\n",
       "caa           int64\n",
       "thall         int64\n",
       "output        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouped the data to X and Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 63.    1.    3.  145.  233.    1.    0.  150.    0.    2.3   0.    0.\n",
      "    1. ]\n",
      " [ 37.    1.    2.  130.  250.    0.    1.  187.    0.    3.5   0.    0.\n",
      "    2. ]\n",
      " [ 41.    0.    1.  130.  204.    0.    0.  172.    0.    1.4   2.    0.\n",
      "    2. ]\n",
      " [ 56.    1.    1.  120.  236.    0.    1.  178.    0.    0.8   2.    0.\n",
      "    2. ]\n",
      " [ 57.    0.    0.  120.  354.    0.    1.  163.    1.    0.6   2.    0.\n",
      "    2. ]]\n",
      "[1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "feature_df = df[['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh', 'exng' , 'oldpeak', \"slp\" ,  'caa', 'thall']]\n",
    "X = np.asarray(feature_df)\n",
    "print(X[0:5])\n",
    "\n",
    "\n",
    "\n",
    "y = np.asarray(df['output'])\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (242, 13) (242,)\n",
      "Test set: (61, 13) (61,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color: red;\">KNN modeling : \n",
    "- #### use all parameters to prediction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy was with 0.7377049180327869 with k= 31\n"
     ]
    }
   ],
   "source": [
    "Ks = 100                                               \n",
    "mean_acc = np.zeros((Ks-1))\n",
    "std_acc = np.zeros((Ks-1))\n",
    "\n",
    "\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat=neigh.predict(X_test)\n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n",
    "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "\n",
    "\n",
    "print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add a magic loop to find the best parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "best_accuracy = 0\n",
    "best_features = None\n",
    "best_k = None\n",
    "\n",
    "# create a list of all feature combinations\n",
    "feature_combinations = []\n",
    "for r in range(1, len(df.columns)-1):\n",
    "    feature_combinations.extend(itertools.combinations(df.columns[:-1], r))\n",
    "\n",
    "# loop through all feature combinations\n",
    "for features in feature_combinations:\n",
    "    feature_df = df[list(features)]\n",
    "    XX = np.asarray(feature_df)\n",
    "    yy = np.asarray(df['output'])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "    Ks = 50\n",
    "    mean_acc = np.zeros((Ks-1))\n",
    "\n",
    "    for n in range(1, Ks):\n",
    "        # Train Model and Predict\n",
    "        neigh = KNeighborsClassifier(n_neighbors=n).fit(X_train, y_train)\n",
    "        yhat = neigh.predict(X_test)\n",
    "        mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n",
    "\n",
    "    # print(f\"Features: {features}\\nBest accuracy: {mean_acc.max()} with k={mean_acc.argmax()+1}\\n\")\n",
    "\n",
    "    # check if this feature subset is the best so far\n",
    "    if mean_acc.max() > best_accuracy:\n",
    "        best_accuracy = mean_acc.max()\n",
    "        best_features = features\n",
    "        best_k = mean_acc.argmax() + 1\n",
    "        print(f\"Features: {features}\\nBest accuracy: {mean_acc.max()} with k={mean_acc.argmax()+1}\\n\")\n",
    "        \n",
    "        \n",
    "print(f\"Best feature subset: {best_features}\\nBest accuracy: {best_accuracy} with k={best_k}\")\n",
    "\n",
    "\n",
    "# output ------------------------------------------------ \n",
    "# Features: ('age',)\n",
    "# Best accuracy: 0.639344262295082 with k=52\n",
    "\n",
    "# Features: ('cp',)\n",
    "# Best accuracy: 0.8032786885245902 with k=3\n",
    "\n",
    "# Features: ('cp', 'restecg')\n",
    "# Best accuracy: 0.819672131147541 with k=28\n",
    "\n",
    "# Features: ('cp', 'oldpeak')\n",
    "# Best accuracy: 0.8360655737704918 with k=13\n",
    "\n",
    "# Features: ('exng', 'caa')\n",
    "# Best accuracy: 0.8688524590163934 with k=7\n",
    "\n",
    "# Features: ('cp', 'exng', 'caa')\n",
    "# Best accuracy: 0.9016393442622951 with k=20\n",
    "\n",
    "# Features: ('cp', 'oldpeak', 'caa', 'thall')\n",
    "# Best accuracy: 0.9180327868852459 with k=20\n",
    "\n",
    "# Features: ('sex', 'cp', 'exng', 'oldpeak', 'slp', 'caa', 'thall')\n",
    "# Best accuracy: 0.9344262295081968 with k=5\n",
    "\n",
    "# Best feature subset: ('sex', 'cp', 'exng', 'oldpeak', 'slp', 'caa', 'thall')\n",
    "# Best accuracy: 0.9344262295081968 with k=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I find the best feature now time to fit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy was with 0.9344262295081968 with k= 4\n"
     ]
    }
   ],
   "source": [
    "feature = df[['sex', 'cp', 'exng', 'oldpeak', 'slp', 'caa', 'thall']]\n",
    "X_train, X_test, y_train, y_test = train_test_split( feature, y, test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "Ks = 5                                               \n",
    "mean_acc = np.zeros((Ks-1))\n",
    "std_acc = np.zeros((Ks-1))\n",
    "\n",
    " \n",
    "neigh = KNeighborsClassifier(n_neighbors = Ks).fit(X_train,y_train)\n",
    "yhat=neigh.predict(X_test)\n",
    "mean_acc[Ks-2] = metrics.accuracy_score(y_test, yhat)\n",
    "std_acc[Ks-2]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "\n",
    "\n",
    "print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### time to test for real parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_parameters = [[1,2,0,0.5,2,0,3]]\n",
    "feature_names = ['sex', 'cp', 'exng', 'oldpeak', 'slp', 'caa', 'thall']\n",
    "real_parameters_with_names = pd.DataFrame(real_parameters, columns=feature_names)\n",
    "neigh.predict(real_parameters_with_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color: red;\">decision tree modeling : \n",
    "- use all parameters to prediction :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (242, 13) (242, 13)\n",
      "Test set: (61, 13) (61,)\n"
     ]
    }
   ],
   "source": [
    "feature_df = df[['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh', 'exng' , 'oldpeak', \"slp\" ,  'caa', 'thall']]\n",
    "X = np.asarray(feature_df)\n",
    "y = np.asarray(df['output'])\n",
    "\n",
    "X_train_Tree, X_test_Tree, y_train_Tree, y_test_Tree = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train_Tree.shape,  X_train_Tree.shape)\n",
    "print ('Test set:', X_test_Tree.shape,  y_test_Tree.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8524590163934426\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "heartTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
    "heartTree.fit(X_train_Tree,y_train_Tree)\n",
    "predTree = heartTree.predict(X_test_Tree)\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test_Tree, predTree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a magic loop to find the best parameters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "best_accuracy = 0\n",
    "best_features = None\n",
    "best_n = None\n",
    "\n",
    "# create a list of all feature combinations\n",
    "feature_combinations = []\n",
    "for r in range(1, len(df.columns)-1):\n",
    "    feature_combinations.extend(itertools.combinations(df.columns[:-1], r))\n",
    "\n",
    "\n",
    "\n",
    "# loop through all feature combinations\n",
    "for features in feature_combinations:\n",
    "    feature_df = df[list(features)]\n",
    "    XX = np.asarray(feature_df)\n",
    "    yy = np.asarray(df['output'])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "    for n in range (1,10) :\n",
    "        heartTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = n)\n",
    "        heartTree.fit(X_train,y_train)\n",
    "        predTree = heartTree.predict(X_test)\n",
    "    \n",
    "    # check if this feature subset is the best so far\n",
    "        if metrics.accuracy_score(y_test, predTree) > best_accuracy:\n",
    "            best_accuracy = metrics.accuracy_score(y_test, predTree)\n",
    "            best_features = features\n",
    "            best_n = n\n",
    "            print(\"Accuracy: \", metrics.accuracy_score(y_test, predTree) , \"feature :\", best_features , best_n)        \n",
    "        \n",
    "        \n",
    "print(\"Best Accuracy: \", best_accuracy , \"best feature :\", best_features , best_n)   \n",
    "\n",
    "\n",
    "\n",
    "# output -----------------------------------------------------------------------------------------------\n",
    "# Accuracy:  0.5901639344262295 feature : ('age',) 1\n",
    "# Accuracy:  0.8032786885245902 feature : ('cp',) 1\n",
    "# Accuracy:  0.819672131147541 feature : ('cp', 'thalachh') 3\n",
    "# Accuracy:  0.8524590163934426 feature : ('exng', 'caa') 2\n",
    "# Accuracy:  0.8688524590163934 feature : ('exng', 'caa') 3\n",
    "# Accuracy:  0.9016393442622951 feature : ('cp', 'caa', 'thall') 4\n",
    "# Accuracy:  0.9180327868852459 feature : ('cp', 'exng', 'slp', 'caa', 'thall') 7\n",
    "# Accuracy:  0.9344262295081968 feature : ('cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall') 7\n",
    "# Best Accuracy:  0.9344262295081968 best feature : ('cp', 'fbs', 'restecg', 'exng', 'slp', 'caa', 'thall') 7    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color: red;\">Logistic Regression : \n",
    "- preprocessing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (242, 13) (242,)\n",
      "Test set: (61, 13) (61,)\n"
     ]
    }
   ],
   "source": [
    "feature_df = df[['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh', 'exng' , 'oldpeak', \"slp\" ,  'caa', 'thall']]\n",
    "X = np.asarray(feature_df)\n",
    "y = np.asarray(df['output'])\n",
    "\n",
    "X_train_LR, X_test_LR, y_train_LR, y_test_LR = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train_LR.shape,  y_train_LR.shape)\n",
    "print ('Test set:', X_test_LR.shape,  y_test_LR.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression(C=2  , solver='liblinear'  ).fit( X_train_LR , y_train_LR )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict Time :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 0 0 1 1 1 1 1\n",
      " 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 0 0 1]\n",
      "[1 0 1 1 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1\n",
      " 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.28663135, 0.71336865],\n",
       "       [0.93936717, 0.06063283],\n",
       "       [0.45332976, 0.54667024],\n",
       "       [0.01705422, 0.98294578],\n",
       "       [0.24396783, 0.75603217],\n",
       "       [0.6751292 , 0.3248708 ],\n",
       "       [0.84812286, 0.15187714],\n",
       "       [0.05634552, 0.94365448],\n",
       "       [0.29127184, 0.70872816],\n",
       "       [0.15649109, 0.84350891],\n",
       "       [0.27100334, 0.72899666],\n",
       "       [0.02992057, 0.97007943],\n",
       "       [0.25201417, 0.74798583],\n",
       "       [0.68189906, 0.31810094],\n",
       "       [0.21338438, 0.78661562],\n",
       "       [0.99437666, 0.00562334],\n",
       "       [0.12317127, 0.87682873],\n",
       "       [0.09870757, 0.90129243],\n",
       "       [0.85985394, 0.14014606],\n",
       "       [0.42157525, 0.57842475],\n",
       "       [0.07868634, 0.92131366],\n",
       "       [0.34697982, 0.65302018],\n",
       "       [0.98402433, 0.01597567],\n",
       "       [0.33429864, 0.66570136],\n",
       "       [0.36227606, 0.63772394],\n",
       "       [0.96928036, 0.03071964],\n",
       "       [0.61358809, 0.38641191],\n",
       "       [0.02497491, 0.97502509],\n",
       "       [0.47976996, 0.52023004],\n",
       "       [0.98975246, 0.01024754],\n",
       "       [0.73268024, 0.26731976],\n",
       "       [0.5339178 , 0.4660822 ],\n",
       "       [0.014614  , 0.985386  ],\n",
       "       [0.1813754 , 0.8186246 ],\n",
       "       [0.29981883, 0.70018117],\n",
       "       [0.03920156, 0.96079844],\n",
       "       [0.07381643, 0.92618357],\n",
       "       [0.3098855 , 0.6901145 ],\n",
       "       [0.50960712, 0.49039288],\n",
       "       [0.99126129, 0.00873871],\n",
       "       [0.9882148 , 0.0117852 ],\n",
       "       [0.93243656, 0.06756344],\n",
       "       [0.94171477, 0.05828523],\n",
       "       [0.36135138, 0.63864862],\n",
       "       [0.0814086 , 0.9185914 ],\n",
       "       [0.24829533, 0.75170467],\n",
       "       [0.95248044, 0.04751956],\n",
       "       [0.70695807, 0.29304193],\n",
       "       [0.92819453, 0.07180547],\n",
       "       [0.07409266, 0.92590734],\n",
       "       [0.97094312, 0.02905688],\n",
       "       [0.49776999, 0.50223001],\n",
       "       [0.92870489, 0.07129511],\n",
       "       [0.45185713, 0.54814287],\n",
       "       [0.13363304, 0.86636696],\n",
       "       [0.00502504, 0.99497496],\n",
       "       [0.07828823, 0.92171177],\n",
       "       [0.10626825, 0.89373175],\n",
       "       [0.99807405, 0.00192595],\n",
       "       [0.95465301, 0.04534699],\n",
       "       [0.02989986, 0.97010014]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_LR = LR.predict(X_test_LR)\n",
    "print(yhat_LR)\n",
    "print(y_test_LR)\n",
    "\n",
    "# predict_proba \n",
    "yhat_prob = LR.predict_proba(X_test_LR)\n",
    "yhat_prob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation ( jaccard index and log loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct prediction percentage of people who want to leave :  0.8717948717948718\n",
      "Correct prediction percentage of people who want to stay  :  0.8148148148148148\n",
      "0.2986984486575867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9180327868852459"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "print( \"Correct prediction percentage of people who want to leave : \", jaccard_score(y_test_LR, yhat_LR,pos_label=1))   \n",
    "print( \"Correct prediction percentage of people who want to stay  : \", jaccard_score(y_test_LR, yhat_LR,pos_label=0))     \n",
    "\n",
    "\n",
    "print(log_loss(y_test_LR, yhat_prob))\n",
    "metrics.accuracy_score(y_test_LR, yhat_LR)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    # print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "# print(confusion_matrix(y_test, yhat, labels=[1,0]))\n",
    "# print (classification_report(y_test, yhat))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test_LR, yhat_LR, labels=[1,0])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['churn=1','churn=0'],normalize= False,  title='Confusion matrix')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a magic loop to find the best accuracy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6885245901639344 feature : ('age',) 1\n",
      "Accuracy:  0.8032786885245902 feature : ('cp',) 1\n",
      "Accuracy:  0.819672131147541 feature : ('cp', 'thalachh') 1\n",
      "Accuracy:  0.8360655737704918 feature : ('exng', 'caa') 1\n",
      "Accuracy:  0.8524590163934426 feature : ('age', 'sex', 'cp') 6\n",
      "Accuracy:  0.8688524590163934 feature : ('age', 'cp', 'restecg') 4\n",
      "Accuracy:  0.8852459016393442 feature : ('age', 'sex', 'cp', 'trtbps') 8\n",
      "Accuracy:  0.9180327868852459 feature : ('age', 'sex', 'cp', 'restecg', 'thalachh') 1\n",
      "Accuracy:  0.9344262295081968 feature : ('age', 'sex', 'cp', 'restecg', 'thalachh', 'exng', 'oldpeak', 'slp', 'caa', 'thall') 1\n",
      "Best Accuracy:  0.9344262295081968 best feature : ('age', 'sex', 'cp', 'restecg', 'thalachh', 'exng', 'oldpeak', 'slp', 'caa', 'thall') 1\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "best_accuracy = 0\n",
    "best_features = None\n",
    "best_c = None\n",
    "\n",
    "# create a list of all feature combinations\n",
    "feature_combinations = []\n",
    "for r in range(1, len(df.columns)-1):\n",
    "    feature_combinations.extend(itertools.combinations(df.columns[:-1], r))\n",
    "\n",
    "\n",
    "\n",
    "# loop through all feature combinations\n",
    "for features in feature_combinations:\n",
    "    feature_df = df[list(features)]\n",
    "    XX = np.asarray(feature_df)\n",
    "    yy = np.asarray(df['output'])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(XX, yy, test_size=0.2, random_state=4)\n",
    "\n",
    "    for c in range (1,10) :\n",
    "        LR = LogisticRegression(C=c  , solver='liblinear'  ).fit( X_train , y_train )\n",
    "        yhat_LR = LR.predict(X_test)\n",
    "        # print(\"Accuracy: \", metrics.accuracy_score(y_test, yhat_LR) , \"feature :\", features , c)\n",
    "    \n",
    "    # check if this feature subset is the best so far\n",
    "        if metrics.accuracy_score(y_test, yhat_LR) > best_accuracy:\n",
    "            best_accuracy = metrics.accuracy_score(y_test, yhat_LR)\n",
    "            best_features = features\n",
    "            best_c = c\n",
    "            print(\"Accuracy: \", metrics.accuracy_score(y_test, yhat_LR) , \"feature :\", best_features , best_c)        \n",
    "        \n",
    "        \n",
    "print(\"Best Accuracy: \", best_accuracy , \"best feature :\", best_features , best_c)   \n",
    "\n",
    "\n",
    "\n",
    "# output -----------------------------------------------------------------------------------------------\n",
    "# Accuracy:  0.6885245901639344 feature : ('age',) 1\n",
    "# Accuracy:  0.8032786885245902 feature : ('cp',) 1\n",
    "# Accuracy:  0.819672131147541 feature : ('cp', 'thalachh') 1\n",
    "# Accuracy:  0.8360655737704918 feature : ('exng', 'caa') 1\n",
    "# Accuracy:  0.8524590163934426 feature : ('age', 'sex', 'cp') 6\n",
    "# Accuracy:  0.8688524590163934 feature : ('age', 'cp', 'restecg') 4\n",
    "# Accuracy:  0.8852459016393442 feature : ('age', 'sex', 'cp', 'trtbps') 8\n",
    "# Accuracy:  0.9180327868852459 feature : ('age', 'sex', 'cp', 'restecg', 'thalachh') 1\n",
    "# Accuracy:  0.9344262295081968 feature : ('age', 'sex', 'cp', 'restecg', 'thalachh', 'exng', 'oldpeak', 'slp', 'caa', 'thall') 1\n",
    "# Best Accuracy:  0.9344262295081968 best feature : ('age', 'sex', 'cp', 'restecg', 'thalachh', 'exng', 'oldpeak', 'slp', 'caa', 'thall') 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit into best feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9344262295081968"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features = df[['age', 'sex', 'cp', 'restecg', 'thalachh', 'exng', 'oldpeak', 'slp', 'caa', 'thall']]\n",
    "X = np.asarray(best_features)\n",
    "y = np.asarray(df['output'])\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "LR = LogisticRegression(C=1  , solver='liblinear').fit( X_train , y_train )\n",
    "yhat = LR.predict(X_test)\n",
    "\n",
    "metrics.accuracy_score(y_test, yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
